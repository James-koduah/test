---
title:
layout: default
permalink: /thoughts/
published: true
---

### Thoughts

Here are scattered thoughts thare are useful.
They range from ideas, quotes from others, observations, a dream I had, opinions. 
They are vignettes, under-developed ideas, like fortune cookies.
Treat with open minds and cautions.

Recent thoughts tends to be on top.

----

[x] do not mistake an approach for a goal. state the goal first, then think about the approach

[x] kevin : in a first meeting with collaborators (undergrads in this case), the meeting should be organized as: 1. intro, who you are, what you do, ect; 2. a set of slides introducing the project; 3. the first task

[x] saujas : three ways of resolving ambiguity are as follows: 1. assume -- agree upon a convention (e.g. rsa derived) 2. clarify -- active learning to ask more question 3. repair -- act with the wrong understanding anyways, and wait for a follow-up fix

[x] alane suhr sayings (in my own paraphrase) : 1. language should only be studied in context, in a task oriented way with measurable outcome. QuestionAnswer is not a task, it is a format. 2. We should study language in context where they're used for tasks we don't expect them to do. An example is from the portal dataset, with "do _that_ again". what does "that" mean? 3. incentive design : what kind of language do you want to elicit? formulate task so these language is what participants will reach for. 4. a trick : if a dyad is successful, make them do more tasks to get more successful data 5. maybe "repair" is the fundamental building block of communication, we're always talking because there are some mis-understanding, and we wouldn't speak if there isn't one. So isn't _that_ the point of communication? shouldn't we be studying iterative response models? 6. non-static benchmarks! 7. confirmatory of instruction validity (so they can be actually followed) 8. mark-up language to refer to "renderable datastructures" such as html, cad, svg, ppt, etc. 

[x] alane : If you're collecting a language dataset, first have a clear idea of the kind of language you want to analyze. Then, structure the task so that this kind of language will be generated by the participants.

[x] a good writer (like judy) can use specific word choices to paint an _appropriately detailed_ image of an abstract concept, such that when others read those words, the image is unambiguous in spaces where the writer want to be precise, and evocative in spaces where the writer intentionally left space for the reader to fill in.

[x] judy: In designing an experiment, always start with X-->Y. X being the iv (independent variable) and Y being the dv (dependent variable). These are special, previledged variables that your experiment is about. Then, there are other design parameters that needs to be fixed, such as complexity of stimuli, etc, in support of the main story. To set the supporting design prameters, more general is always better, but constrained by amount of resource. 

[x] my job is to figure out the abstraction (f) of how people communicate instructions (verbs) to each other in context.

[x] phenomina are high variance and sparse. but they are a consequence of context and function f, e.g. context + f --implies--> phenomina. without understanding of the context and the underlying function, we use distributions to model the phenomina, with data as a last resort. what science is doing is recovering out the context and f, so the process instead of being sparse, is deterministic. every single function (abstraction) we sift through the data is an achievement of science.

[x] in contributing to a project, a weak move (A) is to do a lot of work, then "show off" the work to the team. A pro move is somehow motivate the team so that _they_ do (A) instead.

[x] judy: in contextualizing / situating a complex object (like a research project), always project it down to some axis of variations. For example, mmmCAD can be projected down to the axis of editing tasks (generation vs repair), and modalities (single mode vs multi-modal). mmmCAD is about repair + multi-modal, control-net is about generation + multi-modal, midjourney is about generation + single-modal, etc. this way you have a "turf" mapped out.

Judy Fan herself says "
yeah obviously there are >>2 dimensions .... the purpose of these diagrams is for us silly primates, of course, to highlight what we think is most important for understanding the core issues at stake

so in that way, i think it's risky to go above 2 ... for a conceptual framework. 3 is possible, but it gets very hairy and hard for people to really grok what the core thing is above that

which reflects both: (1) pragmatic/communicative goals -- the value of the speaker highlighting the core issues against the backdrop of other dimensions that are important and (2) cognitive limitations of the audience b/c we are but primates
"

[x] judy: there are certain tasks that are "domesticated" like forced choice, and others that are "wild" i.e. instruction following from drawings.

[x] judy: what (strategies, utterances, cog-stuff ...) do people _"reach for"_ to accomplish (task).

[x] marta: your hypothesis is stronger if it can be validated across multiple different methods

[x] data labeling IS natural program

[x] open-source "freedom" didn't really work out because programming is too hard, and we traded freedom for convinience.

[x] when you speak, don't ever say "I think Y". Always say "Because REASON X, it is that Y". nobody can read your thinkings, so the argument for Y becomes clearer if you first motivate it using X.

[x] Kevin Ellis: bespoke methods come and go a LOT, datasets come and go SOMEWHAT, tasks last FOREVER. Nobody cared for shurdlu's system nor data, but the task of instruction to manipulation stuck around.

[x] in data curation, the one I'm interested in (high quality, expensive data), active learning is important. The idea is, given a data-frame and our current hypotheses, what piece of data should we acquire next? can this be built into an acquisition function so that it is automatic?

[x] HCI + ML is the future. HCI for data gathering and data labeling, building the interface that can serve _twice_, once for data curation, and once for interaction with AI.

[x] In presenting a piece of work, do the following:
- first, model your audience. how can your presentation be helpful to them?
- distill this helpfulness into "goals" you need to hit with your presentation
- based on these goals, _structure_ your presentation around sub-goals, that is the outline
- simultaniously, list all the concepts of your work that you find important to explain
- do a matching algorithm between the list of concepts and the structure of the sub-goals
- don't have to worry about transitions between the slides / passages. the best transition is simply a recap of what you have covered, and what you will cover next.

[x] a presentation could be more like a poem, with more empty negative spaces, and let the audience fill in with their own imagination and excitement. however, what is being written has to be highly defensible and solid.

[x] ask yourself everyday
    - what is my high lvl goal ?
    - what should I do to meet it?
    - keep doing these two and become free of external validations

[x] research is the shortest path to the research question

[x] asking for critiques on presentation / paper, ask both:
    - be cynical and brutal, why would you reject it ?
    - be optimistic and excited, how would you sell it ?

[x] judy fan on how to organize research
    - organize it around sub-goals that you want to hit, an "attack path"

[x] daniel ritche on experiments
    - don't play wack-a-mole with experiments

[x] armando on paper writing
    - every paper is written around a singular idea or concept.

[x] daniel fried on paper writing
    - write it so the setting is more general, and double down if they ask about it (on writing paper with multiple domains)
    - every sentence you re-write, ask yourself : rewrite this sentence to maximize the chance of paper getting accepted
    - make the claim in the abstract / intro as strong and general as possible
    - if you can have a paper where reader can appreciate without understanding technicals, that's how you get a W on inexperienced reviewers
    - minimize confusion --- don't confuse the reader
    - maximize impact --- never undersell it

[x] beilei : 0 point in speaking to prove ur right. 100 point for speaking to accomplish a mutual goal. ppl are not stupid, they know which kind of speaking ur doing right away.

[x] josh : be polite with prior works, "I'm not trying to take away from what's being build, they are impressive, BUT ... "

[x] josh : be conservative with the claims, and upfront with the limitations. I am confident in what I am presenting as a way to get there, but we're not there. Long term road-map, Short term road map.

[x] max : what's the thing a reader should learn from the slide? if they don't learn anything new, remove the slide.

[x] do not use subjective words like "X is important" in writing. that is NOT for you to say, that is for the reader to decide. state the facts, e.g. "X is common".

[x] the value of writing is not to share with the world what's in your head, but to convince they reader how they should see the world differently.

[x] alex / karl : a collaborator should bring something new to the table, they should be able to teach you something. otherwise arnt you working alone ?

[x] josh : give it time, be patient. you'll grow into the researcher you're meant to be.

[x] josh : it is good to frame yourself as someone who does code-generation, but something more interesting on top.

[x] josh : a bad way to do research is "wouldn't it be cool to do X" --- that is a big waste of time. the right way to do research is question driven. what is the research question?

[x] it is better to be firm, and expect your collaborator the same level of standard as yourself.

[x] more important than being nice to students, be fair to students; show the same level of kindness to all students.

[x] it is good to have paper / figure reviews internally in the group to have a standard of the group.

[x] gabe grand : we'll call your figure "the egg man"

[x] old ideas last longer than new ideas into the future. it is often good idea to re-connect with old ideas

[x] in research on a new, challenging area, such as building algorithms that follow human instructions, you want to identify balloon monster problems -- challenging problems that goes pop if you push it slightly with this new technique. this way you can communicate what you're doing is valuable to other people, without sinking too much time into making your research fully fledged.

[x] jiajun : on research, do not waste time. when stuck, identify the key question A to get unstuck -- "you really need to figure out A fast".

[x] children learn concepts, such as "bucket", in very few number of interactions (6 times in their childhood), but the interaction is expansive, consisting of parent playing with the child with the bucket, using it, seeing it at different angles. about 30 minutes of interaction, very rich interactions. the child drives the learning process, manipulating the bucket, seeing it at different angles, and ask questions.

[x] fuzzing programs to test compilers is a good idea. LLM can generate programs, correct or incorrect, to stress test a compiler to see if they are compiled right. the correctness of these programs do not matter.

[x] jesse mu : to make sure model has good alignment with human, you can just ask it more questions, interact with it further, to see if it is still aligned.

[x] marta : a great way to "measure" which tool is better in an open task (i.e. user do w/e they want) is to give the user a choice of tool, and see which they prefer more.

[x] armando: some abstractions (w.r.t. LLM) are easy to translate and make connection to abstractiosn people use, others are outright impossible. humans have many different ways to use language to achieve the same goal.

doing research (around llm as blackbox) is not a game we (armando's group) wants to play. llm is a steam roller, best not stand too close to it.

[x] it is good to be clear about authorship of the paper _as soon as possible_ so that the first author assumes all responsibilities, i.e. the "catch all exception".

[x] you want to make sure collaboration is in agreement on all levels: why -- why are we doing what we're doing? what -- what we're doing in order to meet the why? how -- the actual details. the agreement needs to be done in this order. make sure the team is in agreement on all levels, in this order. otherwise you can't move forward.

[x] accomplishment is cool. getting things done are cool. "I don't care" is not cool at all, as it doesn't actually make anything.

[x] there is a trade-off of automation and flexibility. typically you choose one or the other, but if you do it right you can do both.

[x] good research address a bottleneck of a community that is current. you want to align this with your own interests.

[x] validity = complexity in the right direction. you want to work on valid problems, not arbitrarily complex problems for no good reason.

[x] I think humans place a disporportional amount of importance on energetic systems, as we are intrinstically energy seeking creatures. this reflects in fictions and politics, where we imagine adversaries and violence as our biggest threats -- someone out there to "get us". but the world is energy starved, and most of threats are the lack of energy, the boring dispassionate threat of coldness and starvation.

[x] The Dialectics of Sketching: to _design_ is to plan for the making of something new.

[x] josh: building collaborations with people you can learn from — not just do good work with, but learn from their approaches to research — is very good.

[x] neural models -- good at bullshit almost right answers better than random. programs -- work tirelessly over large input sizes but brittle. reasoning (symbolic or probablistic) -- exhaustive over small domains and accurate, but unscalable. humans -- can do all 3 of the above if given enough time, but is expensive. we need to combine these things together in a truly collaborative system.

[x] I need to work on having a tighter research statement sooner. my iteration speed on projects is lacking, because I explore too much and don't clamp down soon enough. focus on having a clear statement sooner. having people critique my work before all the details are fleshed out is helpful.

[x] Robert Hawkins: as soon as you have a dictionary it becomes out of date. meanings change over time. I wonder what this has to do with how crappy programming language semantics, and DSL are?

[x] tagging an image, providing a label, providing a caption. these are the bricks of the dataset pyramid. these are very regular in "shape" and easy to "stack". however, more interesting interactions, like the way human teach each other, do not have regular "shapes". they are unique experiences and machines don't know how to aggregate or "stack" them. we need to stack these weird but powerful bricks, build systems that can do that.

[x] pyramids are cool. they're cool because it is a physical accumulator. you can explain what makes a pyramid to anyone, an algorithm about moving rocks and placing them, and _everyone_ can execute this algorithm. this shared problem, everyone contributing to it. a good research statement should strive to be the same. A research direction shall be addative. A good way of being addative is by being measurable (think benchmark and dataset) is good, fields that can be measurable improve faster (sam told me this).

[x] programming system should be viewed as a knowledge accumulator. more people interact, more knowledge accumulated within. much like how a person accumulates knowledge. stackoverflow and github are kinda like this, but not quite there. copilot is even further not there.

[x] wisdom of crowd isn't an aggregation over opinions, that is ungrounded and flaccid. wisdom of crowd is sharing a problem that everyone can agree on is important to solve, that a good solution is hard to find, yet apparent once found (think NP). everyone attempts to solve it in their own way. blast out the search space. more people, more likely to find a good solution. that is true wisdom of the crowd. once a solution is found, everyone benefits.

[x] Gerald Sussman said about code/programs along the line of: I can give up general correctness for ease of use right here and now. It's hard to prove general things, so you make a specialized case. But that is brittle.

[x] LLM will suck at playing 20 questions, as it forces a consistent internal model. It will suck even more at playing [situation puzzles](https://en.wikipedia.org/wiki/Situation_puzzle). This will be a very good turing test. If an LLM can play a situation puzzle with a participant, I'd be very surprised and happy. The hilarious part is for a LLM it is very easy to play the role of the oracle in these games, so you can set this up in a self-play way.

[x] a good way to talk about auto-complete is to have the notion of a past set and a future set. the past set is what you've already given the system, and the system's job is to predict the future set. the past set and future set together is the completed thing.

[x] edge is a cool word. in research, what is your edge over other people? what are something only you can do?

[x] Daniel fried said for auto-complete like code, short time-horizon is good, i.e. predict the next thing instead of predicting everything at once. this is intuitive.

[x] abduction -- spinning up a DSL "on the fly" for a particular task is a very important problem. it seems human does this, and it solves the "no DSL closure" issue.

[x] learning via associations is essentially learning with redundancy. two things `A, B`, are given to you, you make some kind of relationship between them (think conditional probability `P(B|A))`. this relationship can be used to recover (partially) one in the absence of another, i.e. redundancy.

[x] beilei on branding: say you're person A. how would someone else, B, explain your work to C? this explanation is basically your brand.

[x] someone in design probably: "whenever someone is using a tool, they're having a conversation with its creator."

[x] josh : "are you evaluating it or you're just guessing?" "is this effect big or small?"

[x] dataset can be same or different. analysis can be same or different. analysis = same dataset, same analysis; replication = different dataset, same analysis; robust is same dataset, different analysis; generalizable is different dataset, different analysis.

[x] leo quoting tao: "once you have the right solution, making it work on something impressive does not scale linearly with efforts." thus, with the right idea, you can push it to something more impressive.

[x] kevin : "interpretable equations have 'units', i.e. F = Gm1m2/rr, whereas the 'equations' implemented in a neural network have no 'units'.

[x] robert : "convention exists in a community, but everyone's experience is personal"

[x] asolar : people re-use primitives in a language because they can be manipulated and understood easily. however, library is essentially a new language and require a lot of effort to learn, thus, people re-implement. loops and if-then-else are pretty common across languages, but the more specific constructs are obscure.

[x] j.carrol on 'naming and cescribing in social communications': 1) the distiction between "name" and "description" is not clear at all, it is a gradient. 2) people reach a "name" through coordination and negotiation, in absence of observation of these processes, a name is unintelligible. 3) the shortening from description to name depends on situation, sometimes it shortens slowly when the set of distractors is difficult, and quickly if only few distractors are present. self note: compare this to programs, where "name" is function-name, and "description" is in a sense a function's body.

[x] josh : "the goal of the abstract is to get the right people interested in reading the paper, but not to overpromise. who should read this paper and why?"

[x] robert : you can give data to psych people in two forms. wide-form, where each user is 1 row cllapsed in a style of json dictionary. long-form, where each unit of analysis is 1 row expanded out (R likes this form more).

[x] marta : when you get data, first thing to do is to do _descriptive statistics_ such as number of participants, average length of descriptions, etc.

[x] josh : "the most striking thing about our data is ...". "this quantitative result can _carry_ the paper alone.

[x] josh : have a hypothesis before going out to collect data, think deeply before going yolo.

[x] in collaboration it is helpful to explain straightforwardly what difficulty _you_ currently have, so everyone is on the same page. also asks other to explain theirs. share these difficulties, share these "cost functions" and optimize together.

[x] alex bishara : if you want to amplify a direction of research, it should be done in a manner that is irrelevant if people continue to work with you or not. ultimately they should be able to go in that direction independently.

[x] robert hawkins : the other approaches are not competition, but a "foil" which we can use to contextualize our own works.

[x] josh : what is the question? how should we answer them? in another words, can you show me a plot, and how the plot turned up will answer the question one way or another?

[x] "hold strong opinions loosely"